services:
  llm-api-for-next-chat:
    build: .
    image: llm-api-for-next-chat/llm-api-for-next-chat:latest
    container_name: llm-api-for-next-chat
    ports:
      - 5000:5000
    restart: unless-stopped
    volumes:
      - ./chatgpt_web/file_cache.json:/app/chatgpt_web/file_cache.json
      - ./theb_ai/Theb_API.json:/app/theb_ai/Theb_API.json
      - ./hugging_chat/config.json:/app/hugging_chat/config.json
      - ./generated_images:/app/generated_images
      - .env:/app/.env
      - ./docker-compose.yml:/app/docker-compose.yml
      - ./scripts:/app/scripts
    networks:
      - llms_api

  chatgpt-next-web:
    image: yidadaa/chatgpt-next-web:v2.15.7
    container_name: chatgpt-next-web
    restart: unless-stopped
    ports:
      - 3030:3000
    environment:
      BASE_URL: http://llm-api-for-next-chat:5000/api/openai
      ANTHROPIC_URL: http://llm-api-for-next-chat:5000/api/anthropic
      DEEPSEEK_URL: http://llm-api-for-next-chat:5000/api/openai/v1
      CUSTOM_MODELS: |-
        -all,
        o4-mini@OpenAI,
        o3@OpenAI,
        o3-mini@OpenAI,
        o1@OpenAI,
        o1-mini@OpenAI,
        gpt-5-chat@OpenAI,
        gpt-5@OpenAI,
        gpt-5-mini@OpenAI,
        gpt-4.1@OpenAI,
        gpt-4.1-mini@OpenAI,
        gpt-4o@OpenAI,
        gpt-4o-mini@OpenAI,
        gemini-2.5-pro@Google,
        gemini-2.5-flash@Google,
        gemini-2.5-flash-lite@Google,
        gemini-2.0-flash@Google,
        gemini-2.0-flash-lite@Google,
        deepseek-v3.2-exp@DeepSeek,
        glm-4.6@ZhipuAI,
        kat-dev@Kwaipilot,
        qwen3-vl-235b-a22b-instruct@Qwen,
        deepseek-v3.1-terminus@DeepSeek,
        qwen3-vl-235b-a22b-thinking@Qwen,
        glm-4.6-fp8@ZhipuAI,
        qwen3-235b-a22b-thinking-2507@Qwen,
        qwen3-next-80b-a3b-instruct@Qwen,
        qwen3-next-80b-a3b-thinking@Qwen,
        kimi-k2-instruct-0905@KimiAI,
        gpt-oss-20b@OpenAI,
        apertus-8b-instruct-2509@Apertus,
        gpt-oss-120b@OpenAI,
        qwen3-coder-30b-a3b-instruct@Qwen,
        llama-3.1-8b-instruct@Meta,
        qwen2.5-vl-7b-instruct@Qwen,
        qwen3-30b-a3b-instruct-2507@Qwen,
        ernie-4.5-vl-28b-a3b-pt@Baidu,
        ernie-4.5-0.3b-pt@Baidu,
        deepseek-r1@DeepSeek,
        ernie-4.5-21b-a3b-pt@Baidu,
        apertus-70b-instruct-2509@Apertus,
        qwen3-4b-instruct-2507@Qwen,
        llama-3.2-3b-instruct@Meta,
        qwen3-coder-480b-a35b-instruct@Qwen,
        meta-llama-3-8b-instruct@Meta,
        qwen3-4b-thinking-2507@Qwen,
        kimi-k2-instruct@KimiAI,
        glm-4.5v@ZhipuAI,
        deepseek-v3.1@DeepSeek,
        qwen3-8b@Qwen,
        qwen3-30b-a3b-thinking-2507@Qwen,
        gemma-3-27b-it@Gemma,
        glm-4.5-air@ZhipuAI,
        smollm3-3b@HuggingFaceTB,
        qwen3-30b-a3b@Qwen,
        qwen2.5-7b-instruct@Qwen,
        qwen3-32b@Qwen,
        qwq-32b@Qwen,
        qwen3-235b-a22b-instruct-2507@Qwen,
        llama-3.3-70b-instruct@Meta,
        qwen2.5-vl-32b-instruct@Qwen,
        deepseek-r1-distill-qwen-1.5b@Qwen,
        qwen3-235b-a22b@Qwen,
        llama-4-scout-17b-16e-instruct@Meta,
        hermes-4-70b@NousResearch,
        qwen2.5-coder-32b-instruct@Qwen,
        arch-router-1.5b@Katanemo,
        llama-3.2-1b-instruct@Meta,
        deepseek-r1-distill-qwen-7b@Qwen,
        deepseek-v3@DeepSeek,
        deepseek-v3-0324@DeepSeek,
        command-a-translate-08-2025@CohereLabs,
        deepseek-r1-distill-qwen-32b@Qwen,
        ernie-4.5-vl-424b-a47b-base-pt@Baidu,
        llama-4-maverick-17b-128e-instruct@Meta,
        qwen3-coder-480b-a35b-instruct-fp8@Qwen,
        deepseek-r1-0528-qwen3-8b@Qwen,
        deepseek-r1-0528@DeepSeek,
        qwen3-14b@Qwen,
        minimax-m1-80k@MinimaxAI,
        qwen2.5-coder-7b-instruct@Qwen,
        gemma-sea-lion-v4-27b-it@Gemma,
        aya-expanse-8b@CohereLabs,
        baichuan-m2-32b@BaichuanAI,
        qwen2.5-vl-72b-instruct@Qwen,
        llama-4-maverick-17b-128e-instruct-fp8@Meta,
        glm-4.1v-9b-thinking@ZhipuAI,
        glm-4.5-air-fp8@ZhipuAI,
        gemma-2-2b-it@Gemma,
        afm-4.5b@ArceeAI,
        deepseek-r1-distill-llama-8b@Meta,
        aya-vision-8b@CohereLabs,
        hermes-3-llama-3.1-405b@Meta,
        qwen2.5-72b-instruct@Qwen,
        llama-guard-4-12b@Meta,
        command-a-vision-07-2025@CohereLabs,
        llama-3_1-nemotron-ultra-253b-v1@Meta,
        meta-llama-3-70b-instruct@Meta,
        hermes-4-405b@NousResearch,
        hermes-2-pro-llama-3-8b@Meta,
        gemma-2-9b-it@Gemma,
        l3-8b-stheno-v3.2@Sao10K,
        cogito-v2-preview-llama-109b-moe@Meta,
        c4ai-command-r-08-2024@CohereLabs,
        ernie-4.5-300b-a47b-base-pt@Baidu,
        aya-expanse-32b@CohereLabs,
        c4ai-command-a-03-2025@CohereLabs,
        command-a-reasoning-08-2025@CohereLabs,
        wizardlm-2-8x22b@Microsoft,
        llama-3.3-swallow-70b-instruct-v0.4@Meta,
        deepseek-r1-distill-llama-70b@Meta,
        c4ai-command-r7b-12-2024@CohereLabs,
        l3-70b-euryale-v2.1@Sao10K,
        aya-vision-32b@CohereLabs,
        llama-3.1-405b-instruct@Meta,
        c4ai-command-r7b-arabic-02-2025@CohereLabs,
        l3-8b-lunaris-v1@Sao10K,
        qwen2.5-coder-7b@Qwen,
        qwq-32b-preview@Qwen,
        deepseek-r1-distill-qwen-14b@Qwen,
        llama-3.1-70b-instruct@Meta,
        qwen3-235b-a22b-fp8@Qwen,
        glm-4-32b-0414@ZhipuAI,
        dobby-unhinged-llama-3.3-70b@Meta,
        marin-8b-instruct@Marin,
        deepseek-prover-v2-671b@DeepSeek,
        hermes-3-llama-3.1-70b@Meta,
        qwen2.5-coder-3b-instruct@Qwen,
        cogito-v2-preview-llama-70b@Meta,
        cogito-v2-preview-llama-405b@Meta,
        cogito-v2-preview-deepseek-671b-moe@DeepSeek
    env_file:
      - .env
    networks:
      - llms_api

  monitor:
    image: docker:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./docker-compose.yml:/app/docker-compose.yml
      - .env:/app/.env
      - ./scripts:/app/scripts
    command: sh -c "chmod +x /app/scripts/monitor.sh && /app/scripts/monitor.sh"
    depends_on:
      - llm-api-for-next-chat
    networks:
      - llms_api

networks:
  llms_api:
    name: llms_api
